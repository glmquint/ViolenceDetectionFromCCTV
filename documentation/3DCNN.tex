\chapter{3D CNN approach}
\label{chapter:3D}
\section{Introduction}
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{./images/3DCNN.png}
    \caption{How a 3D CNN works}
    \label{fig:How3DCNNWorks}
\end{figure}

2D CNN networks operate by applying convolutions spatially, traversing both the horizontal and vertical dimensions of the input data. The convolutional operation employs 2D kernels, usually specified in terms of height and width. Channels, representing different aspects of the input data (e.g., Red, Green, Blue in color images), are a common feature of 2D CNNs.

On the other hand, 3D CNNs extend the convolutional approach to three-dimensional data, a structure commonly found in video or volumetric datasets. The input to a 3D CNN includes not only width and height but also a third dimension, often representing depth or frames in the temporal domain. Consequently, the kernels used in 3D CNNs are three-dimensional, incorporating depth, height, and width. This extension allows the model to capture spatial features across multiple frames, introducing a temporal aspect to the convolutional operation. This makes them particularly suitable for tasks involving video analysis and scenarios where temporal information is crucial like our \textit{violence recognition} problem.

While 2D CNNs have proven effective for traditional image-related tasks like classification, object detection, and segmentation, 3D CNNs are specifically designed for applications where temporal information is essential. However, the use of 3D CNNs comes at a higher computational cost due to the increased complexity introduced by the additional dimension. This would have proved to be a problem for us due to the fact that we did not have a GPU at our disposal and the ones provided by Google Colab were not capable enough to handle big models and big data-sets.

\section{Implementation}
As explained in section \ref{framextraction}, the pickles approach allowed us to generate files containing the data needed to train and test the model. The \textit{number of frames} and the \textit{fps} values for each pkl\_config were used to test the same model on different input data like burst of 1, 2 or 3 seconds. As shown in Fig. \ref{fig:3DCNNschema}, the model is a very simple one, with 2 convolutional layers, 2 max pooling layers and 1 fully connected. The idea is not to dwell on the model and how to improve it, but to show that the addition of "context" to the input data, in this case the temporal dimension, allows the model to achieve better results independently from the complexity of the model.
\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.6\textwidth, keepaspectratio]{images/3D9CNNschema.png}
    \caption{Schema of the first 3D CNN}
    \label{fig:3DCNNschema}
\end{figure}

The very first test was done with a number of frames (NoF) equal to 5 and fps equal to 5, meaning that the model would receive bursts of 1 second. Fig. \ref{fig:First3DCNNconfusionMatrix} shows an interesting result, it is very similar to the best 2D scratch one with a slightly better recall score in general.

\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth]{images/7f2d-testGiacomo3D9-9fcf-conf_matrix.png}
    \caption{Confusion matrix of the first 3D model}
    \label{fig:First3DCNNconfusionMatrix}
\end{figure}

The second test was done with NoF equal to 10 and fps equal to 5, meaning that the model would receive bursts of 2 seconds. This was done to see if the model would improve with more context, since 1 second of video does not carry much information. 

\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ce07-testGiacomo3D3-9fcf-conf_matrix.png}
    \caption{Confusion matrix of the second 3D model with 2 seconds bursts}
    \label{fig:Second3DCNNconfusionMatrix}
\end{figure}

Finally the third test was done with NoF equal to 15 and fps equal to 5, meaning that the model would receive bursts of 3 seconds. Keep in mind, however, that since some of the original dataset is made of videos shorter than 3 seconds both training and test sets are reduced. This means that results are to be taken lightly since they are not representative of the original dataset. In addition the previous model had to be simplified to avoid making it too complex for the smaller dataset, the new schema can be seen in Fig. \ref{fig:3D3CNNschema}. The results shown in Fig. \ref{fig:Third3DCNNconfusionMatrix} are the best one so far, with a very good recall score for both classes. This is due to the fact that the model has more context to work with and can better understand the situation.

\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.6\textwidth, keepaspectratio]{images/3D9CNNschema.png}
    \caption{Schema of the second 3D CNN}
    \label{fig:3D3CNNschema}
\end{figure}


\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth]{images/71d5-testGiacomo3D3-9fcf-conf_matrix.png}
    \caption{Confusion matrix of the second 3D model with 3 seconds burst}
    \label{fig:Third3DCNNconfusionMatrix}
\end{figure}



\chapter{Conclusion}
Finally a table with the accuracy of all the models can be seen in Tab. \ref{tab:3DCNNtable}. This proves that the 3D CNN approach is valid and that it can be used as an alternative to the 2D one. However, the 3D approach is more computationally expensive and requires more time to train and test, but it can achieve better results. Another thing to keep in mind is that the 3D approach seems to gain from longer bursts of frames, giving the model more "context". This means that the 3D method is more suitable for real time analysis of CCTV footage, where the model receives bursts of frames and is able to decide if there is violence or not by analyzing the evolution of the features over time. This is not the case for the 2D CNN approach that is more suitable for static images, where the model is able to decide if there is violence or not by analyzing the features of a single frame, but it is not able to understand the evolution of the action over time.

\begin{table}[h]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|c|c|c|c|}
    \cline{2-5}
                                                             & \textbf{Frame burst} & \textbf{Accuracy} & \textbf{Violence recall} & \textbf{Non violence recall} \\ \hline
    \multicolumn{1}{|c|}{\textbf{Best 2D scratch}}           & Single frame & 0,62619            & 0,49048                   & 0,7619 \\ \hline
    \multicolumn{1}{|c|}{\textbf{Best ResNet50}}               & Single frame & 0,7643            & 0,6952                   & 0,8333                       \\ \hline
    \multicolumn{1}{|c|}{\textbf{Best EfficientNetB0}} & Single frame & 0,7833            & 0,8762                   & 0,6905                       \\ \hline
    \multicolumn{1}{|c|}{\textbf{First 3D model}}            & 1 second burst & 0,7074            & 0,5744                   & 0,8404                       \\ \hline
    \multicolumn{1}{|c|}{\textbf{Second 3D model}}           & 2 seconds burst & 0,7532            & 0,7468                   & 0,7595                       \\ \hline
    \multicolumn{1}{|c|}{\textbf{Second 3D model}}            & 3 seconds burst & 0,8065            & 0,8710                   & 0,7419                       \\ \hline
    \end{tabular}%
    }
    \caption{Models accuracy}
    \label{tab:3DCNNtable}
\end{table}
